{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part_4: Stroke_Prediction - Tensorflow linear classifier \n",
    "7:45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Heart_Disease</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Type_Of_Work</th>\n",
       "      <th>Residence</th>\n",
       "      <th>Avg_Glucose</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking_Status</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>Age_years</th>\n",
       "      <th>Age_years_10</th>\n",
       "      <th>Gender_C</th>\n",
       "      <th>Ever_Married_C</th>\n",
       "      <th>Type_Of_Work_C</th>\n",
       "      <th>Residence_C</th>\n",
       "      <th>Smoking_Status_C</th>\n",
       "      <th>Age_years_10_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30650</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>87.96</td>\n",
       "      <td>39.2</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "      <td>58.093151</td>\n",
       "      <td>(53.126, 59.076]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>57008</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>69.04</td>\n",
       "      <td>35.9</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>0</td>\n",
       "      <td>70.076712</td>\n",
       "      <td>(65.121, 74.11]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     ID  Gender  Hypertension  Heart_Disease Ever_Married  \\\n",
       "0           0  30650    Male             1              0          Yes   \n",
       "1           1  57008  Female             0              0          Yes   \n",
       "\n",
       "  Type_Of_Work Residence  Avg_Glucose   BMI   Smoking_Status  Stroke  \\\n",
       "0      Private     Urban        87.96  39.2     never smoked       0   \n",
       "1      Private     Rural        69.04  35.9  formerly smoked       0   \n",
       "\n",
       "   Age_years      Age_years_10  Gender_C  Ever_Married_C  Type_Of_Work_C  \\\n",
       "0  58.093151  (53.126, 59.076]         1               1               2   \n",
       "1  70.076712   (65.121, 74.11]         0               1               2   \n",
       "\n",
       "   Residence_C  Smoking_Status_C  Age_years_10_C  \n",
       "0            1                 1               5  \n",
       "1            0                 0               7  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df= pd.read_csv('c:/1/Stroke_Prediction_NUM.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Analiza poziomu zbilansowania zmiennej wynikowej</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.981144\n",
       "1    0.018856\n",
       "Name: Stroke, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df['Unnamed: 0']\n",
    "df.Stroke.value_counts(dropna = False, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbiór zmiennych wynikowych wymaga zbilansowania. Do bilansowania zmiennych wynikowych stosuję trzy metody:\n",
    "- class_weight (http://sigmaquality.pl/models/classification/logistic-regression/model-regresji-logistyczne-czesc-4-zastosowanie-class_weight/)\n",
    "-  oversampling (http://sigmaquality.pl/models/classification/logistic-regression/model-regresji-logistycznej-czesc-2-oversampling/)\n",
    "- zmiana progu (http://sigmaquality.pl/models/classification/logistic-regression/model-regresji-logistycznej-czesc-3-zmiana-progu-w-modelu-regresji-logistycznej/)\n",
    "\n",
    "Wszystkie trzy metody powinny dać podobne efekty przy klasyfikacji. Dzisiaj do zbilansowania zbioru zastosuje metodę oversampling. Oversampling odbywa się na zbiorze treningowym więc najpierw trzeba podzielić zbiór na treningowy i testowy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Podział na zbiór testowy i wynikowy</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['Hypertension','Heart_Disease','Avg_Glucose','BMI','Stroke','Age_years','Gender_C','Ever_Married_C','Type_Of_Work_C','Residence_C','Smoking_Status_C','Age_years_10_C']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df2['Stroke']\n",
    "X = df2.drop('Stroke', axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zbiór X treningowy:  (19471, 11)\n",
      "Zbiór X testowy:     (9591, 11)\n",
      "Zbiór y treningowy:  (19471,)\n",
      "Zbiór y testowy:     (9591,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y, test_size=0.33, stratify = y, random_state = 148)\n",
    "\n",
    "print ('Zbiór X treningowy: ',Xtrain.shape)\n",
    "print ('Zbiór X testowy:    ', Xtest.shape)\n",
    "print ('Zbiór y treningowy: ', ytrain.shape)\n",
    "print ('Zbiór y testowy:    ', ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ytrain = 0:  19104\n",
      "ytrain = 1:  367\n"
     ]
    }
   ],
   "source": [
    "print(\"ytrain = 0: \", sum(ytrain == 0))\n",
    "print(\"ytrain = 1: \", sum(ytrain == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ilość 0 Stroke na 1 Stroke:  52\n"
     ]
    }
   ],
   "source": [
    "Proporcja = sum(ytrain == 0) / sum(ytrain == 1) \n",
    "Proporcja = np.round(Proporcja, decimals=0)\n",
    "Proporcja = Proporcja.astype(int)\n",
    "print('Ilość 0 Stroke na 1 Stroke: ', Proporcja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19084"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_OVSA = pd.concat([ytrain[ytrain==1]] * Proporcja, axis = 0) \n",
    "ytrain_OVSA.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powiękrzyliśmy ilość zmiennych wynikowych 1. Teraz mamy tą samą liczbę wierszy zmiennych wynikowych i zmiennych niezależnych. Teraz wprowadzamy nowe, dodatkowe zmienne 1 do zbioru treningowego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19084"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_OVSA = pd.concat([Xtrain.loc[ytrain==1, :]] * Proporcja, axis = 0)\n",
    "ytrain_OVSA.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ilość elementów w zbiorze Xtrain:      19471\n",
      "ilość elementów w zbiorze Xtrain_OVSA:  38555\n",
      "ilość elementów w zbiorze ytrain:      19471\n",
      "ilość elementów w zbiorze ytrain_OVSA:  38555\n"
     ]
    }
   ],
   "source": [
    "ytrain_OVSA = pd.concat([ytrain, ytrain_OVSA], axis = 0).reset_index(drop = True)\n",
    "Xtrain_OVSA = pd.concat([Xtrain, Xtrain_OVSA], axis = 0).reset_index(drop = True)\n",
    "\n",
    "print(\"ilość elementów w zbiorze Xtrain:     \", Xtrain.BMI.count())\n",
    "print(\"ilość elementów w zbiorze Xtrain_OVSA: \", Xtrain_OVSA.BMI.count())\n",
    "print(\"ilość elementów w zbiorze ytrain:     \", ytrain.count())\n",
    "print(\"ilość elementów w zbiorze ytrain_OVSA: \", ytrain_OVSA.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poziom zbilansowania zbioru wynikowego:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x26587452f60>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ytrain_OVSA.value_counts(dropna = False, normalize=True).plot(kind='pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Oversampling dla zbioru testowego</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ytest = 0:  9410\n",
      "ytest = 1:  181\n"
     ]
    }
   ],
   "source": [
    "print(\"ytest = 0: \", sum(ytest == 0))\n",
    "print(\"ytest = 1: \", sum(ytest == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ilość 0 Stroke na 1 Stroke:  52\n"
     ]
    }
   ],
   "source": [
    "ProporcjaT = sum(ytrain == 0) / sum(ytrain == 1) \n",
    "ProporcjaT = np.round(ProporcjaT, decimals=0)\n",
    "ProporcjaT = Proporcja.astype(int)\n",
    "print('Ilość 0 Stroke na 1 Stroke: ', ProporcjaT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9412"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest_OVSA = pd.concat([ytest[ytest==1]] * ProporcjaT, axis = 0) \n",
    "ytest_OVSA.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9412"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_OVSA = pd.concat([Xtest.loc[ytest==1, :]] * ProporcjaT, axis = 0)\n",
    "ytest_OVSA.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ilość elementów w zbiorze Xtrain:      9591\n",
      "ilość elementów w zbiorze Xtrain_OVSA:  19003\n",
      "ilość elementów w zbiorze ytrain:      9591\n",
      "ilość elementów w zbiorze ytrain_OVSA:  19003\n"
     ]
    }
   ],
   "source": [
    "ytest_OVSA = pd.concat([ytest, ytest_OVSA], axis = 0).reset_index(drop = True)\n",
    "Xtest_OVSA = pd.concat([Xtest, Xtest_OVSA], axis = 0).reset_index(drop = True)\n",
    "\n",
    "print(\"ilość elementów w zbiorze Xtrain:     \", Xtest.BMI.count())\n",
    "print(\"ilość elementów w zbiorze Xtrain_OVSA: \", Xtest_OVSA.BMI.count())\n",
    "print(\"ilość elementów w zbiorze ytrain:     \", ytest.count())\n",
    "print(\"ilość elementów w zbiorze ytrain_OVSA: \", ytest_OVSA.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Tensorflow neural network</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\OLD_TF\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\OLD_TF\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\OLD_TF\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\OLD_TF\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\OLD_TF\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\OLD_TF\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tensorflow Version 1.5.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Using tensorflow Version %s\" %tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29062, 12)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_column = tf.contrib.layers.real_valued_column('features', dimension=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Definiowanie estymatora</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'kernel_e', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002658C996358>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.LinearClassifier(feature_columns=[feat_column],\n",
    "                                          n_classes=2,\n",
    "                                          model_dir = \"kernel_e\"\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zmiana wszystkich zmiennych numerycznych na zmienne TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Hypertension', 'Heart_Disease', 'Avg_Glucose', 'BMI', 'Stroke',\n",
       "       'Age_years', 'Gender_C', 'Ever_Married_C', 'Type_Of_Work_C',\n",
       "       'Residence_C', 'Smoking_Status_C', 'Age_years_10_C'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='Hypertension', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='Heart_Disease', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='Avg_Glucose', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='BMI', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='Stroke', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='Age_years', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='Gender_C', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='Ever_Married_C', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='Type_Of_Work_C', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='Residence_C', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='Smoking_Status_C', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='Age_years_10_C', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURES  = ['Hypertension', 'Heart_Disease', 'Avg_Glucose', 'BMI', 'Stroke',\n",
    "       'Age_years', 'Gender_C', 'Ever_Married_C', 'Type_Of_Work_C',\n",
    "       'Residence_C', 'Smoking_Status_C', 'Age_years_10_C']\n",
    "\n",
    "continuous_features = [tf.feature_column.numeric_column(k) for k in FEATURES]\n",
    "continuous_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Definiuje klasyfikator liniowy</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'ongoing/ATOS7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002658A86F320>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.LinearClassifier(\n",
    "    n_classes = 2,\n",
    "    model_dir=\"ongoing/ATOS7\", \n",
    "    feature_columns=continuous_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Tworze funkcję wprowadzania</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['Hypertension', 'Heart_Disease', 'Avg_Glucose', 'BMI', 'Stroke',\n",
    "       'Age_years', 'Gender_C', 'Ever_Married_C', 'Type_Of_Work_C',\n",
    "       'Residence_C', 'Smoking_Status_C', 'Age_years_10_C']\n",
    "LABEL = 'Stroke'\n",
    "\n",
    "def get_input_fn(data_set, num_epochs=None, n_batch = 128, shuffle=True):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "       x=pd.DataFrame({k: data_set[k].values for k in FEATURES}),\n",
    "       y = pd.Series(data_set[LABEL].values),\n",
    "       batch_size=n_batch,   \n",
    "       num_epochs=num_epochs,\n",
    "       shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Trenowanie modelu</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([Xtrain_OVSA, ytrain_OVSA], axis=1, sort=False) \n",
    "df_test = pd.concat([Xtest_OVSA, ytest_OVSA], axis=1, sort=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ongoing/ATOS7\\model.ckpt-21000\n",
      "INFO:tensorflow:Saving checkpoints for 21001 into ongoing/ATOS7\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.17566305, step = 21001\n",
      "INFO:tensorflow:global_step/sec: 309.824\n",
      "INFO:tensorflow:loss = 0.08458078, step = 21101 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.103\n",
      "INFO:tensorflow:loss = 0.10183035, step = 21201 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.839\n",
      "INFO:tensorflow:loss = 0.03914675, step = 21301 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 358.161\n",
      "INFO:tensorflow:loss = 0.093212485, step = 21401 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.96\n",
      "INFO:tensorflow:loss = 0.058216006, step = 21501 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.023\n",
      "INFO:tensorflow:loss = 0.023705248, step = 21601 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.06\n",
      "INFO:tensorflow:loss = 0.13911867, step = 21701 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.81\n",
      "INFO:tensorflow:loss = 0.099779435, step = 21801 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.948\n",
      "INFO:tensorflow:loss = 0.04130444, step = 21901 (0.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.982\n",
      "INFO:tensorflow:loss = 0.11200627, step = 22001 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.92\n",
      "INFO:tensorflow:loss = 0.078409396, step = 22101 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.308\n",
      "INFO:tensorflow:loss = 0.02320021, step = 22201 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.159\n",
      "INFO:tensorflow:loss = 0.18642974, step = 22301 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.89\n",
      "INFO:tensorflow:loss = 0.07380908, step = 22401 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.7\n",
      "INFO:tensorflow:loss = 0.034611046, step = 22501 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.562\n",
      "INFO:tensorflow:loss = 0.09768262, step = 22601 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.925\n",
      "INFO:tensorflow:loss = 0.115870595, step = 22701 (0.332 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.175\n",
      "INFO:tensorflow:loss = 0.027746651, step = 22801 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.495\n",
      "INFO:tensorflow:loss = 0.10048109, step = 22901 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 314.153\n",
      "INFO:tensorflow:loss = 0.06618851, step = 23001 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.033\n",
      "INFO:tensorflow:loss = 0.025598232, step = 23101 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.089\n",
      "INFO:tensorflow:loss = 0.11467208, step = 23201 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.136\n",
      "INFO:tensorflow:loss = 0.12112671, step = 23301 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.964\n",
      "INFO:tensorflow:loss = 0.04274956, step = 23401 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.001\n",
      "INFO:tensorflow:loss = 0.08887144, step = 23501 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.972\n",
      "INFO:tensorflow:loss = 0.07307571, step = 23601 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.884\n",
      "INFO:tensorflow:loss = 0.022211503, step = 23701 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.245\n",
      "INFO:tensorflow:loss = 0.116128616, step = 23801 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.819\n",
      "INFO:tensorflow:loss = 0.102194265, step = 23901 (0.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 332.243\n",
      "INFO:tensorflow:loss = 0.04164597, step = 24001 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.233\n",
      "INFO:tensorflow:loss = 0.11707689, step = 24101 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.25\n",
      "INFO:tensorflow:loss = 0.091995455, step = 24201 (0.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.802\n",
      "INFO:tensorflow:loss = 0.02726069, step = 24301 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.419\n",
      "INFO:tensorflow:loss = 0.10180294, step = 24401 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.019\n",
      "INFO:tensorflow:loss = 0.08382518, step = 24501 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.576\n",
      "INFO:tensorflow:loss = 0.031759486, step = 24601 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.857\n",
      "INFO:tensorflow:loss = 0.094535604, step = 24701 (0.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.809\n",
      "INFO:tensorflow:loss = 0.14583683, step = 24801 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.316\n",
      "INFO:tensorflow:loss = 0.033070937, step = 24901 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.377\n",
      "INFO:tensorflow:loss = 0.088789515, step = 25001 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.254\n",
      "INFO:tensorflow:loss = 0.07540406, step = 25101 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.545\n",
      "INFO:tensorflow:loss = 0.023486897, step = 25201 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.389\n",
      "INFO:tensorflow:loss = 0.09445211, step = 25301 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 336.452\n",
      "INFO:tensorflow:loss = 0.13933605, step = 25401 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.582\n",
      "INFO:tensorflow:loss = 0.043850582, step = 25501 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.506\n",
      "INFO:tensorflow:loss = 0.0973307, step = 25601 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.844\n",
      "INFO:tensorflow:loss = 0.10285395, step = 25701 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.38\n",
      "INFO:tensorflow:loss = 0.02147673, step = 25801 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.863\n",
      "INFO:tensorflow:loss = 0.12469642, step = 25901 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.506\n",
      "INFO:tensorflow:loss = 0.115765095, step = 26001 (0.305 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.676\n",
      "INFO:tensorflow:loss = 0.04309678, step = 26101 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 322.71\n",
      "INFO:tensorflow:loss = 0.100031406, step = 26201 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.069\n",
      "INFO:tensorflow:loss = 0.13623369, step = 26301 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.927\n",
      "INFO:tensorflow:loss = 0.028593421, step = 26401 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 341.332\n",
      "INFO:tensorflow:loss = 0.116974995, step = 26501 (0.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.3\n",
      "INFO:tensorflow:loss = 0.09474189, step = 26601 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.041\n",
      "INFO:tensorflow:loss = 0.029520823, step = 26701 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.781\n",
      "INFO:tensorflow:loss = 0.1079755, step = 26801 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 324.272\n",
      "INFO:tensorflow:loss = 0.17143114, step = 26901 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.786\n",
      "INFO:tensorflow:loss = 0.039674632, step = 27001 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 300.138\n",
      "INFO:tensorflow:loss = 0.10469595, step = 27101 (0.333 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.983\n",
      "INFO:tensorflow:loss = 0.09012644, step = 27201 (0.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.648\n",
      "INFO:tensorflow:loss = 0.025580343, step = 27301 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.141\n",
      "INFO:tensorflow:loss = 0.11406425, step = 27401 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.18\n",
      "INFO:tensorflow:loss = 0.18171939, step = 27501 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.782\n",
      "INFO:tensorflow:loss = 0.043850783, step = 27601 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.985\n",
      "INFO:tensorflow:loss = 0.11610725, step = 27701 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.212\n",
      "INFO:tensorflow:loss = 0.13268626, step = 27801 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 331.362\n",
      "INFO:tensorflow:loss = 0.02495951, step = 27901 (0.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.962\n",
      "INFO:tensorflow:loss = 0.09864132, step = 28001 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.112\n",
      "INFO:tensorflow:loss = 0.12653358, step = 28101 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.538\n",
      "INFO:tensorflow:loss = 0.039827023, step = 28201 (0.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 340.526\n",
      "INFO:tensorflow:loss = 0.096462965, step = 28301 (0.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.487\n",
      "INFO:tensorflow:loss = 0.19557756, step = 28401 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 318.231\n",
      "INFO:tensorflow:loss = 0.030913629, step = 28501 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 315.992\n",
      "INFO:tensorflow:loss = 0.123502865, step = 28601 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.484\n",
      "INFO:tensorflow:loss = 0.12796819, step = 28701 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.31\n",
      "INFO:tensorflow:loss = 0.02940876, step = 28801 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.519\n",
      "INFO:tensorflow:loss = 0.112104885, step = 28901 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 339.588\n",
      "INFO:tensorflow:loss = 0.21159783, step = 29001 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.751\n",
      "INFO:tensorflow:loss = 0.045232877, step = 29101 (0.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.742\n",
      "INFO:tensorflow:loss = 0.11734075, step = 29201 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.81\n",
      "INFO:tensorflow:loss = 0.1327774, step = 29301 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.451\n",
      "INFO:tensorflow:loss = 0.025403937, step = 29401 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 338.882\n",
      "INFO:tensorflow:loss = 0.102663726, step = 29501 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 334.752\n",
      "INFO:tensorflow:loss = 0.21302441, step = 29601 (0.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 310.804\n",
      "INFO:tensorflow:loss = 0.04676579, step = 29701 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 317.611\n",
      "INFO:tensorflow:loss = 0.123240076, step = 29801 (0.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.958\n",
      "INFO:tensorflow:loss = 0.19300595, step = 29901 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.81\n",
      "INFO:tensorflow:loss = 0.027662415, step = 30001 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.397\n",
      "INFO:tensorflow:loss = 0.12987056, step = 30101 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 321.164\n",
      "INFO:tensorflow:loss = 0.18477467, step = 30201 (0.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.41\n",
      "INFO:tensorflow:loss = 0.03829936, step = 30301 (0.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.555\n",
      "INFO:tensorflow:loss = 0.11940849, step = 30401 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.325\n",
      "INFO:tensorflow:loss = 0.3323355, step = 30501 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.414\n",
      "INFO:tensorflow:loss = 0.03280564, step = 30601 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.762\n",
      "INFO:tensorflow:loss = 0.10867426, step = 30701 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 330.257\n",
      "INFO:tensorflow:loss = 0.18233678, step = 30801 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.595\n",
      "INFO:tensorflow:loss = 0.029090181, step = 30901 (0.292 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 31000 into ongoing/ATOS7\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.10506183.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x265fc406c88>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=get_input_fn(df_train, \n",
    "                                num_epochs=None,\n",
    "                                n_batch = 128,\n",
    "                                shuffle=False),\n",
    "                                steps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Ocena modelu</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-03-03-10:11:05\n",
      "INFO:tensorflow:Restoring parameters from ongoing/ATOS7\\model.ckpt-31000\n",
      "INFO:tensorflow:Evaluation [100/1000]\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-03-10:11:06\n",
      "INFO:tensorflow:Saving dict for global step 31000: accuracy = 1.0, accuracy_baseline = 0.50481504, auc = 1.0, auc_precision_recall = 1.0, average_loss = 0.002097592, global_step = 31000, label/mean = 0.50481504, loss = 0.2675204, prediction/mean = 0.5035834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 1.0,\n",
       " 'accuracy_baseline': 0.50481504,\n",
       " 'auc': 1.0,\n",
       " 'auc_precision_recall': 1.0,\n",
       " 'average_loss': 0.002097592,\n",
       " 'label/mean': 0.50481504,\n",
       " 'loss': 0.2675204,\n",
       " 'prediction/mean': 0.5035834,\n",
       " 'global_step': 31000}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(input_fn=get_input_fn(df_test, \n",
    "                                      num_epochs=1,\n",
    "                                      n_batch = 128,\n",
    "                                      shuffle=False),\n",
    "                                      steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.predict(    \n",
    "         input_fn=get_input_fn(df_test,                          \n",
    "         num_epochs=1,                          \n",
    "         n_batch = 256,                          \n",
    "         shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Estimator.predict at 0x000002658EE2D728>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph('ongoing/ATOS7')\n",
    "    print(\"Model found.\")\n",
    "\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "    print(\"Model restored compl.\")\n",
    "\n",
    "    z = tf.placeholder(tf.float32, shape= (None,38555))\n",
    "\n",
    "    y_pred= y_pred.as_matrix()\n",
    "\n",
    "    output =sess.run(z,feed_dict={Xtest_OVSA: y_pred})\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' objects are mutable, thus they cannot be hashed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-22735ab28bae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mXtest_OVSA\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\OLD_TF\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1884\u001b[0m         raise TypeError(\n\u001b[0;32m   1885\u001b[0m             \u001b[1;34m\"{0!r} objects are mutable, thus they cannot be\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1886\u001b[1;33m             \u001b[1;34m\" hashed\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1887\u001b[0m         )\n\u001b[0;32m   1888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DataFrame' objects are mutable, thus they cannot be hashed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 2654\n"
     ]
    }
   ],
   "source": [
    "output =sess.run(y,feed_dict={Xtest_OVSA: y_pred})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
