{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part_5: Stroke_Prediction - Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Heart_Disease</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Type_Of_Work</th>\n",
       "      <th>Residence</th>\n",
       "      <th>Avg_Glucose</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking_Status</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>Age_years</th>\n",
       "      <th>Age_years_10</th>\n",
       "      <th>Gender_C</th>\n",
       "      <th>Ever_Married_C</th>\n",
       "      <th>Type_Of_Work_C</th>\n",
       "      <th>Residence_C</th>\n",
       "      <th>Smoking_Status_C</th>\n",
       "      <th>Age_years_10_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30650</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>87.96</td>\n",
       "      <td>39.2</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "      <td>58.093151</td>\n",
       "      <td>(53.126, 59.076]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>57008</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>69.04</td>\n",
       "      <td>35.9</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>0</td>\n",
       "      <td>70.076712</td>\n",
       "      <td>(65.121, 74.11]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     ID  Gender  Hypertension  Heart_Disease Ever_Married  \\\n",
       "0           0  30650    Male             1              0          Yes   \n",
       "1           1  57008  Female             0              0          Yes   \n",
       "\n",
       "  Type_Of_Work Residence  Avg_Glucose   BMI   Smoking_Status  Stroke  \\\n",
       "0      Private     Urban        87.96  39.2     never smoked       0   \n",
       "1      Private     Rural        69.04  35.9  formerly smoked       0   \n",
       "\n",
       "   Age_years      Age_years_10  Gender_C  Ever_Married_C  Type_Of_Work_C  \\\n",
       "0  58.093151  (53.126, 59.076]         1               1               2   \n",
       "1  70.076712   (65.121, 74.11]         0               1               2   \n",
       "\n",
       "   Residence_C  Smoking_Status_C  Age_years_10_C  \n",
       "0            1                 1               5  \n",
       "1            0                 0               7  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df= pd.read_csv('c:/1/Stroke_Prediction_NUM.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Analiza poziomu zbilansowania zmiennej wynikowej</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.981144\n",
       "1    0.018856\n",
       "Name: Stroke, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df['Unnamed: 0']\n",
    "df.Stroke.value_counts(dropna = False, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbiór zmiennych wynikowych wymaga zbilansowania. Do bilansowania zmiennych wynikowych stosuję trzy metody:\n",
    "- class_weight (http://sigmaquality.pl/models/classification/logistic-regression/model-regresji-logistyczne-czesc-4-zastosowanie-class_weight/)\n",
    "-  oversampling (http://sigmaquality.pl/models/classification/logistic-regression/model-regresji-logistycznej-czesc-2-oversampling/)\n",
    "- zmiana progu (http://sigmaquality.pl/models/classification/logistic-regression/model-regresji-logistycznej-czesc-3-zmiana-progu-w-modelu-regresji-logistycznej/)\n",
    "\n",
    "Wszystkie trzy metody powinny dać podobne efekty przy klasyfikacji. Dzisiaj do zbilansowania zbioru zastosuje metodę oversampling. Oversampling odbywa się na zbiorze treningowym, więc najpierw trzeba podzielić zbiór na treningowy i testowy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Podział na zbiór testowy i wynikowy</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['Hypertension','Heart_Disease','Avg_Glucose','BMI','Stroke','Age_years','Gender_C','Ever_Married_C','Type_Of_Work_C','Residence_C','Smoking_Status_C','Age_years_10_C']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df2['Stroke']\n",
    "X = df2.drop('Stroke', axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zbiór X treningowy:  (19471, 11)\n",
      "Zbiór X testowy:     (9591, 11)\n",
      "Zbiór y treningowy:  (19471,)\n",
      "Zbiór y testowy:     (9591,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y, test_size=0.33, stratify = y, random_state = 148)\n",
    "\n",
    "print ('Zbiór X treningowy: ',Xtrain.shape)\n",
    "print ('Zbiór X testowy:    ', Xtest.shape)\n",
    "print ('Zbiór y treningowy: ', ytrain.shape)\n",
    "print ('Zbiór y testowy:    ', ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ytrain = 0:  19104\n",
      "ytrain = 1:  367\n"
     ]
    }
   ],
   "source": [
    "print(\"ytrain = 0: \", sum(ytrain == 0))\n",
    "print(\"ytrain = 1: \", sum(ytrain == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ilość 0 Stroke na 1 Stroke:  52\n"
     ]
    }
   ],
   "source": [
    "Proporcja = sum(ytrain == 0) / sum(ytrain == 1) \n",
    "Proporcja = np.round(Proporcja, decimals=0)\n",
    "Proporcja = Proporcja.astype(int)\n",
    "print('Ilość 0 Stroke na 1 Stroke: ', Proporcja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19084"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_OVSA = pd.concat([ytrain[ytrain==1]] * Proporcja, axis = 0) \n",
    "ytrain_OVSA.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powiękrzyliśmy ilość zmiennych wynikowych 1. Teraz mamy tę samą liczbę wierszy zmiennych wynikowych i zmiennych niezależnych. Teraz wprowadzamy nowe, dodatkowe zmienne 1 do zbioru treningowego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19084"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_OVSA = pd.concat([Xtrain.loc[ytrain==1, :]] * Proporcja, axis = 0)\n",
    "ytrain_OVSA.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ilość elementów w zbiorze Xtrain:      19471\n",
      "ilość elementów w zbiorze Xtrain_OVSA:  38555\n",
      "ilość elementów w zbiorze ytrain:      19471\n",
      "ilość elementów w zbiorze ytrain_OVSA:  38555\n"
     ]
    }
   ],
   "source": [
    "ytrain_OVSA = pd.concat([ytrain, ytrain_OVSA], axis = 0).reset_index(drop = True)\n",
    "Xtrain_OVSA = pd.concat([Xtrain, Xtrain_OVSA], axis = 0).reset_index(drop = True)\n",
    "\n",
    "print(\"ilość elementów w zbiorze Xtrain:     \", Xtrain.BMI.count())\n",
    "print(\"ilość elementów w zbiorze Xtrain_OVSA: \", Xtrain_OVSA.BMI.count())\n",
    "print(\"ilość elementów w zbiorze ytrain:     \", ytrain.count())\n",
    "print(\"ilość elementów w zbiorze ytrain_OVSA: \", ytrain_OVSA.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poziom zbilansowania zbioru wynikowego:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1898e757438>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ytrain_OVSA.value_counts(dropna = False, normalize=True).plot(kind='pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Oversampling dla zbioru testowego</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ytest = 0:  9410\n",
      "ytest = 1:  181\n"
     ]
    }
   ],
   "source": [
    "print(\"ytest = 0: \", sum(ytest == 0))\n",
    "print(\"ytest = 1: \", sum(ytest == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ilość 0 Stroke na 1 Stroke:  52\n"
     ]
    }
   ],
   "source": [
    "ProporcjaT = sum(ytrain == 0) / sum(ytrain == 1) \n",
    "ProporcjaT = np.round(ProporcjaT, decimals=0)\n",
    "ProporcjaT = Proporcja.astype(int)\n",
    "print('Ilość 0 Stroke na 1 Stroke: ', ProporcjaT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9412"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest_OVSA = pd.concat([ytest[ytest==1]] * ProporcjaT, axis = 0) \n",
    "ytest_OVSA.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9412"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_OVSA = pd.concat([Xtest.loc[ytest==1, :]] * ProporcjaT, axis = 0)\n",
    "ytest_OVSA.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ilość elementów w zbiorze Xtrain:      9591\n",
      "ilość elementów w zbiorze Xtrain_OVSA:  19003\n",
      "ilość elementów w zbiorze ytrain:      9591\n",
      "ilość elementów w zbiorze ytrain_OVSA:  19003\n"
     ]
    }
   ],
   "source": [
    "ytest_OVSA = pd.concat([ytest, ytest_OVSA], axis = 0).reset_index(drop = True)\n",
    "Xtest_OVSA = pd.concat([Xtest, Xtest_OVSA], axis = 0).reset_index(drop = True)\n",
    "\n",
    "print(\"ilość elementów w zbiorze Xtrain:     \", Xtest.BMI.count())\n",
    "print(\"ilość elementów w zbiorze Xtrain_OVSA: \", Xtest_OVSA.BMI.count())\n",
    "print(\"ilość elementów w zbiorze ytrain:     \", ytest.count())\n",
    "print(\"ilość elementów w zbiorze ytrain_OVSA: \", ytest_OVSA.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Tensorflow neural network</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\OLD_TF\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\OLD_TF\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\OLD_TF\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\OLD_TF\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\OLD_TF\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\OLD_TF\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tensorflow Version 1.5.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Using tensorflow Version %s\" %tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29062, 12)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_column = tf.contrib.layers.real_valued_column('features', dimension=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Definiowanie estymatora</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'kernel_e', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001899EA56278>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.LinearClassifier(feature_columns=[feat_column],\n",
    "                                          n_classes=2,\n",
    "                                          model_dir = \"kernel_e\"\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zmiana wszystkich zmiennych numerycznych na zmienne TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Hypertension', 'Heart_Disease', 'Avg_Glucose', 'BMI', 'Stroke',\n",
       "       'Age_years', 'Gender_C', 'Ever_Married_C', 'Type_Of_Work_C',\n",
       "       'Residence_C', 'Smoking_Status_C', 'Age_years_10_C'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='Hypertension', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='Heart_Disease', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='Avg_Glucose', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='BMI', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='Stroke', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='Age_years', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='Gender_C', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='Ever_Married_C', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='Type_Of_Work_C', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='Residence_C', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='Smoking_Status_C', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='Age_years_10_C', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURES  = ['Hypertension', 'Heart_Disease', 'Avg_Glucose', 'BMI', 'Stroke',\n",
    "       'Age_years', 'Gender_C', 'Ever_Married_C', 'Type_Of_Work_C',\n",
    "       'Residence_C', 'Smoking_Status_C', 'Age_years_10_C']\n",
    "\n",
    "continuous_features = [tf.feature_column.numeric_column(k) for k in FEATURES]\n",
    "continuous_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Definiuje klasyfikator liniowy</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'ongoing/ATOS7', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001899CBC0400>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.LinearClassifier(\n",
    "    n_classes = 2,\n",
    "    model_dir=\"ongoing/ATOS7\", \n",
    "    feature_columns=continuous_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Tworzę funkcję wprowadzania</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['Hypertension', 'Heart_Disease', 'Avg_Glucose', 'BMI', 'Stroke',\n",
    "       'Age_years', 'Gender_C', 'Ever_Married_C', 'Type_Of_Work_C',\n",
    "       'Residence_C', 'Smoking_Status_C', 'Age_years_10_C']\n",
    "LABEL = 'Stroke'\n",
    "\n",
    "def get_input_fn(data_set, num_epochs=None, n_batch = 128, shuffle=True):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "       x=pd.DataFrame({k: data_set[k].values for k in FEATURES}),\n",
    "       y = pd.Series(data_set[LABEL].values),\n",
    "       batch_size=n_batch,   \n",
    "       num_epochs=num_epochs,\n",
    "       shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Trenowanie modelu</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([Xtrain_OVSA, ytrain_OVSA], axis=1, sort=False) \n",
    "df_test = pd.concat([Xtest_OVSA, ytest_OVSA], axis=1, sort=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ongoing/ATOS7\\model.ckpt-41000\n",
      "INFO:tensorflow:Saving checkpoints for 41001 into ongoing/ATOS7\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.09737757, step = 41001\n",
      "INFO:tensorflow:global_step/sec: 259.654\n",
      "INFO:tensorflow:loss = 0.045715436, step = 41101 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.305\n",
      "INFO:tensorflow:loss = 0.08216881, step = 41201 (0.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.039\n",
      "INFO:tensorflow:loss = 0.033824317, step = 41301 (0.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.722\n",
      "INFO:tensorflow:loss = 0.06005334, step = 41401 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.798\n",
      "INFO:tensorflow:loss = 0.04598384, step = 41501 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.258\n",
      "INFO:tensorflow:loss = 0.019679055, step = 41601 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.451\n",
      "INFO:tensorflow:loss = 0.07859419, step = 41701 (0.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 156.504\n",
      "INFO:tensorflow:loss = 0.08064161, step = 41801 (0.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.75\n",
      "INFO:tensorflow:loss = 0.034247227, step = 41901 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.794\n",
      "INFO:tensorflow:loss = 0.077103004, step = 42001 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.328\n",
      "INFO:tensorflow:loss = 0.064075656, step = 42101 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.466\n",
      "INFO:tensorflow:loss = 0.019486569, step = 42201 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.435\n",
      "INFO:tensorflow:loss = 0.08544526, step = 42301 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.663\n",
      "INFO:tensorflow:loss = 0.058666773, step = 42401 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 298.415\n",
      "INFO:tensorflow:loss = 0.028867826, step = 42501 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.599\n",
      "INFO:tensorflow:loss = 0.07046058, step = 42601 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.38\n",
      "INFO:tensorflow:loss = 0.0941832, step = 42701 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.419\n",
      "INFO:tensorflow:loss = 0.024095044, step = 42801 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 151.92\n",
      "INFO:tensorflow:loss = 0.06935177, step = 42901 (0.669 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.366\n",
      "INFO:tensorflow:loss = 0.0517662, step = 43001 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.004\n",
      "INFO:tensorflow:loss = 0.02210995, step = 43101 (0.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 185.903\n",
      "INFO:tensorflow:loss = 0.06902549, step = 43201 (0.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.076\n",
      "INFO:tensorflow:loss = 0.094448306, step = 43301 (0.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.803\n",
      "INFO:tensorflow:loss = 0.036873564, step = 43401 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.478\n",
      "INFO:tensorflow:loss = 0.064160794, step = 43501 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.134\n",
      "INFO:tensorflow:loss = 0.057811715, step = 43601 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.219\n",
      "INFO:tensorflow:loss = 0.018571634, step = 43701 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 293.18\n",
      "INFO:tensorflow:loss = 0.082472146, step = 43801 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 287.599\n",
      "INFO:tensorflow:loss = 0.07906988, step = 43901 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.474\n",
      "INFO:tensorflow:loss = 0.03498091, step = 44001 (0.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.475\n",
      "INFO:tensorflow:loss = 0.07337621, step = 44101 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 297.663\n",
      "INFO:tensorflow:loss = 0.073616184, step = 44201 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.016\n",
      "INFO:tensorflow:loss = 0.02367942, step = 44301 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.955\n",
      "INFO:tensorflow:loss = 0.06778104, step = 44401 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.578\n",
      "INFO:tensorflow:loss = 0.06666125, step = 44501 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.48\n",
      "INFO:tensorflow:loss = 0.026955485, step = 44601 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.954\n",
      "INFO:tensorflow:loss = 0.06536393, step = 44701 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.627\n",
      "INFO:tensorflow:loss = 0.11598677, step = 44801 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 176.839\n",
      "INFO:tensorflow:loss = 0.028442333, step = 44901 (0.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.504\n",
      "INFO:tensorflow:loss = 0.062104367, step = 45001 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.168\n",
      "INFO:tensorflow:loss = 0.05752158, step = 45101 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.55\n",
      "INFO:tensorflow:loss = 0.020415168, step = 45201 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.649\n",
      "INFO:tensorflow:loss = 0.07284053, step = 45301 (0.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 296.648\n",
      "INFO:tensorflow:loss = 0.10609268, step = 45401 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 289.163\n",
      "INFO:tensorflow:loss = 0.03753686, step = 45501 (0.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.183\n",
      "INFO:tensorflow:loss = 0.07539731, step = 45601 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.723\n",
      "INFO:tensorflow:loss = 0.0807307, step = 45701 (0.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.707\n",
      "INFO:tensorflow:loss = 0.018085375, step = 45801 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.478\n",
      "INFO:tensorflow:loss = 0.08718066, step = 45901 (0.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 299.305\n",
      "INFO:tensorflow:loss = 0.088378854, step = 46001 (0.334 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.039\n",
      "INFO:tensorflow:loss = 0.036748014, step = 46101 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.242\n",
      "INFO:tensorflow:loss = 0.07226403, step = 46201 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.208\n",
      "INFO:tensorflow:loss = 0.105186135, step = 46301 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.749\n",
      "INFO:tensorflow:loss = 0.024719864, step = 46401 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.123\n",
      "INFO:tensorflow:loss = 0.08536232, step = 46501 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 306.63\n",
      "INFO:tensorflow:loss = 0.07138116, step = 46601 (0.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.728\n",
      "INFO:tensorflow:loss = 0.024890233, step = 46701 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.694\n",
      "INFO:tensorflow:loss = 0.08181512, step = 46801 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.761\n",
      "INFO:tensorflow:loss = 0.13006693, step = 46901 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.324\n",
      "INFO:tensorflow:loss = 0.03466392, step = 47001 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.324\n",
      "INFO:tensorflow:loss = 0.076379016, step = 47101 (0.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 281.65\n",
      "INFO:tensorflow:loss = 0.066052586, step = 47201 (0.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.451\n",
      "INFO:tensorflow:loss = 0.021731038, step = 47301 (0.522 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.884\n",
      "INFO:tensorflow:loss = 0.07308343, step = 47401 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.905\n",
      "INFO:tensorflow:loss = 0.13414271, step = 47501 (0.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.044\n",
      "INFO:tensorflow:loss = 0.036732923, step = 47601 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.955\n",
      "INFO:tensorflow:loss = 0.0743381, step = 47701 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.841\n",
      "INFO:tensorflow:loss = 0.096731044, step = 47801 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.97\n",
      "INFO:tensorflow:loss = 0.020686347, step = 47901 (0.571 sec)\n",
      "INFO:tensorflow:global_step/sec: 169.37\n",
      "INFO:tensorflow:loss = 0.07160351, step = 48001 (0.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.861\n",
      "INFO:tensorflow:loss = 0.09029151, step = 48101 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.685\n",
      "INFO:tensorflow:loss = 0.033549923, step = 48201 (0.709 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.466\n",
      "INFO:tensorflow:loss = 0.06933582, step = 48301 (0.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.821\n",
      "INFO:tensorflow:loss = 0.14186579, step = 48401 (0.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.539\n",
      "INFO:tensorflow:loss = 0.026808614, step = 48501 (0.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.75\n",
      "INFO:tensorflow:loss = 0.0859948, step = 48601 (0.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.989\n",
      "INFO:tensorflow:loss = 0.08885132, step = 48701 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.971\n",
      "INFO:tensorflow:loss = 0.024762977, step = 48801 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.821\n",
      "INFO:tensorflow:loss = 0.08615236, step = 48901 (0.519 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 282.444\n",
      "INFO:tensorflow:loss = 0.14492016, step = 49001 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 304.765\n",
      "INFO:tensorflow:loss = 0.039036565, step = 49101 (0.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.512\n",
      "INFO:tensorflow:loss = 0.08584847, step = 49201 (0.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.317\n",
      "INFO:tensorflow:loss = 0.08690578, step = 49301 (0.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.904\n",
      "INFO:tensorflow:loss = 0.021082029, step = 49401 (0.342 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.035\n",
      "INFO:tensorflow:loss = 0.07428626, step = 49501 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.928\n",
      "INFO:tensorflow:loss = 0.14064331, step = 49601 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 291.475\n",
      "INFO:tensorflow:loss = 0.03935333, step = 49701 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.039\n",
      "INFO:tensorflow:loss = 0.09069357, step = 49801 (0.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.727\n",
      "INFO:tensorflow:loss = 0.1264919, step = 49901 (0.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.37\n",
      "INFO:tensorflow:loss = 0.023504142, step = 50001 (0.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.528\n",
      "INFO:tensorflow:loss = 0.096213445, step = 50101 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.752\n",
      "INFO:tensorflow:loss = 0.11533563, step = 50201 (0.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.559\n",
      "INFO:tensorflow:loss = 0.032153483, step = 50301 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.468\n",
      "INFO:tensorflow:loss = 0.09044957, step = 50401 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.851\n",
      "INFO:tensorflow:loss = 0.20495865, step = 50501 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 292.326\n",
      "INFO:tensorflow:loss = 0.028214257, step = 50601 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 301.103\n",
      "INFO:tensorflow:loss = 0.08116261, step = 50701 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.568\n",
      "INFO:tensorflow:loss = 0.10606042, step = 50801 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 295.773\n",
      "INFO:tensorflow:loss = 0.024945365, step = 50901 (0.335 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 51000 into ongoing/ATOS7\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.07768929.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x189995d8208>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=get_input_fn(df_train, \n",
    "                                num_epochs=None,\n",
    "                                n_batch = 128,\n",
    "                                shuffle=False),\n",
    "                                steps=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Ocena modelu</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-03-03-10:49:24\n",
      "INFO:tensorflow:Restoring parameters from ongoing/ATOS7\\model.ckpt-51000\n",
      "INFO:tensorflow:Evaluation [100/1000]\n",
      "INFO:tensorflow:Finished evaluation at 2020-03-03-10:49:25\n",
      "INFO:tensorflow:Saving dict for global step 51000: accuracy = 1.0, accuracy_baseline = 0.50481504, auc = 1.0, auc_precision_recall = 1.0, average_loss = 0.0007520476, global_step = 51000, label/mean = 0.50481504, loss = 0.09591383, prediction/mean = 0.5047147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 1.0,\n",
       " 'accuracy_baseline': 0.50481504,\n",
       " 'auc': 1.0,\n",
       " 'auc_precision_recall': 1.0,\n",
       " 'average_loss': 0.0007520476,\n",
       " 'label/mean': 0.50481504,\n",
       " 'loss': 0.09591383,\n",
       " 'prediction/mean': 0.5047147,\n",
       " 'global_step': 51000}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(input_fn=get_input_fn(df_test, \n",
    "                                      num_epochs=1,\n",
    "                                      n_batch = 128,\n",
    "                                      shuffle=False),\n",
    "                                      steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.predict(    \n",
    "         input_fn=get_input_fn(df_test,                          \n",
    "         num_epochs=1,                          \n",
    "         n_batch = 256,                          \n",
    "         shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Estimator.predict at 0x000001899EFF25C8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">Pobranie modelu z grafu i klasyfikacja na danych testowych</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar  3 11:49:25 2020\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time() ## pomiar czasu: start pomiaru czasu\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph('ongoing/ATOS7')\n",
    "    print(\"Model found.\")\n",
    "\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "    print(\"Model restored compl.\")\n",
    "\n",
    "    #z = tf.placeholder(tf.float32, shape= (None,38555))\n",
    "\n",
    "    y_pred= y_pred.as_matrix()\n",
    "    \n",
    "    output =sess.run(y,feed_dict={Xtest_OVSA: y_pred})\n",
    "\n",
    "    #output =sess.run(z,feed_dict={Xtest_OVSA: y_pred})\n",
    "    #print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Pomiar czasu wykonania tego zadania')\n",
    "print(time.time() - start_time) ## koniec pomiaru czasu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
