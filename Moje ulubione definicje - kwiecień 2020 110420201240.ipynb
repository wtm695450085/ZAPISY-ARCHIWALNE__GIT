{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moje ulubione definicje - kwiecie≈Ñ 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Oversampling</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampling(ytrain, Xtrain):\n",
    "    import matplotlib.pyplot as plt\n",
    "       \n",
    "    \n",
    "    print(\"y = 0: \", sum(ytrain == 0))\n",
    "    print(\"y = 1: \", sum(ytrain == 1))\n",
    "    print('--------------------------------------------------------')\n",
    "    \n",
    "    ytrain.value_counts(dropna = False, normalize=True).plot(kind='pie',title='Before oversampling')\n",
    "    plt.show\n",
    "    print()\n",
    "    \n",
    "    Proporcja = sum(ytrain == 0) / sum(ytrain == 1) \n",
    "    Proporcja = np.round(Proporcja, decimals=0)\n",
    "    Proporcja = Proporcja.astype(int)\n",
    "        \n",
    "    ytrain_OV = pd.concat([ytrain[ytrain==1]] * Proporcja, axis = 0) \n",
    "    Xtrain_OV = pd.concat([Xtrain.loc[ytrain==1, :]] * Proporcja, axis = 0)\n",
    "    \n",
    "    ytrain_OV = pd.concat([ytrain, ytrain_OV], axis = 0).reset_index(drop = True)\n",
    "    Xtrain_OV = pd.concat([Xtrain, Xtrain_OV], axis = 0).reset_index(drop = True)\n",
    "    \n",
    "    \n",
    "    print(\"Before oversampling Xtrain:     \", Xtrain.shape)\n",
    "    print(\"Before oversampling ytrain:     \", ytrain.shape)\n",
    "    print('--------------------------------------------------------')\n",
    "    print(\"After oversampling Xtrain_OV:  \", Xtrain_OV.shape)\n",
    "    print(\"After oversampling ytrain_OV:  \", ytrain_OV.shape)\n",
    "    print('--------------------------------------------------------')\n",
    "        \n",
    "    ax = plt.subplot(1, 2, 1)\n",
    "    ytrain.value_counts(dropna = False, normalize=True).plot(kind='pie',title='Before oversampling')\n",
    "    plt.show\n",
    "    ax = plt.subplot(1, 2, 2)\n",
    "    ytrain_OV.value_counts(dropna = False, normalize=True).plot(kind='pie',title='After oversampling')\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Classification Assessment</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Assessment\n",
    "def Classification_Assessment(model ,Xtrain, ytrain, Xtest, ytest):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn import metrics\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    from sklearn.metrics import confusion_matrix, log_loss, auc, roc_curve, roc_auc_score, recall_score, precision_recall_curve\n",
    "    from sklearn.metrics import make_scorer, precision_score, fbeta_score, f1_score, classification_report\n",
    "    \n",
    "    import scikitplot as skplt\n",
    "    from plot_metric.functions import BinaryClassification\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "       \n",
    "    print(\"Recall Training data:     \", np.round(recall_score(ytrain, model.predict(Xtrain)), decimals=4))\n",
    "    print(\"Precision Training data:  \", np.round(precision_score(ytrain, model.predict(Xtrain)), decimals=4))\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(\"Recall Test data:         \", np.round(recall_score(ytest, model.predict(Xtest)), decimals=4)) \n",
    "    print(\"Precision Test data:      \", np.round(precision_score(ytest, model.predict(Xtest)), decimals=4))\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print(\"Confusion Matrix Test data\")\n",
    "    print(confusion_matrix(ytest, model.predict(Xtest)))\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print('Valuation for test data only:')\n",
    "    print(classification_report(ytest, model.predict(Xtest)))\n",
    "    \n",
    "    ## ----------AUC-----------------------------------------\n",
    "     \n",
    "    print('---------------------') \n",
    "    AUC_train_1 = metrics.roc_auc_score(ytrain,model.predict_proba(Xtrain)[:,1])\n",
    "    print('AUC_train: %.3f' % AUC_train_1)\n",
    "    AUC_test_1 = metrics.roc_auc_score(ytest,model.predict_proba(Xtest)[:,1])\n",
    "    print('AUC_test:  %.3f' % AUC_test_1)\n",
    "    print('---------------------')    \n",
    "    \n",
    "    print(\"Accuracy Training data:     \", np.round(accuracy_score(ytrain, model.predict(Xtrain)), decimals=4))\n",
    "    print(\"Accuracy Test data:         \", np.round(accuracy_score(ytest, model.predict(Xtest)), decimals=4)) \n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    print('Valuation for test data only:')\n",
    "\n",
    "    y_probas1 = model.predict_proba(Xtest)[:,1]\n",
    "    y_probas2 = model.predict_proba(Xtest)\n",
    "\n",
    "### ---plot_roc_curve--------------------------------------------------------\n",
    "    plt.figure(figsize=(13,4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    bc = BinaryClassification(ytest, y_probas1, labels=[\"Class 1\", \"Class 2\"])\n",
    "    bc.plot_roc_curve() \n",
    "\n",
    "\n",
    "### --------precision_recall_curve------------------------------------------\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    precision, recall, thresholds = precision_recall_curve(ytest, y_probas1)\n",
    "\n",
    "    plt.plot(recall, precision, marker='.', label=model)\n",
    "    plt.title('Precision recall curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend(loc=(-0.30, -0.6))\n",
    "    plt.show()\n",
    "\n",
    "## ----------plot_roc-----------------------------------------\n",
    "\n",
    "    skplt.metrics.plot_roc(ytest, y_probas2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">Colorful prints</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  colorful prints\n",
    "def black(text):\n",
    "     print('\\033[30m', text, '\\033[0m', sep='')  \n",
    "def red(text):\n",
    "     print('\\033[31m', text, '\\033[0m', sep='')  \n",
    "def green(text):\n",
    "     print('\\033[32m', text, '\\033[0m', sep='')  \n",
    "def yellow(text):     \n",
    "    print('\\033[33m', text, '\\033[0m', sep='')  \n",
    "def blue(text):\n",
    "     print('\\033[34m', text, '\\033[0m', sep='') \n",
    "def magenta(text):\n",
    "     print('\\033[35m', text, '\\033[0m', sep='')  \n",
    "def cyan(text):\n",
    "     print('\\033[36m', text, '\\033[0m', sep='')  \n",
    "def gray(text):\n",
    "     print('\\033[90m', text, '\\033[0m', sep='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
